{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepath</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22457</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/disgust/train_0543...</td>\n",
       "      <td>disgust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44080</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/happy/train_03946_...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5516</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/test/happy/PrivateTest_6...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48241</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/angry/Training_161...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48214</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/neutral/Training_9...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44811</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/test/happy/PublicTest_14...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45062</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/surprise/Training_...</td>\n",
       "      <td>surprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5300</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/fear/Training_3563...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26121</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/test/happy/test_1143_ali...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16031</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/test/angry/PublicTest_38...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/happy/Training_107...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44126</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/happy/Training_365...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31241</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/angry/Training_238...</td>\n",
       "      <td>angry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30017</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/happy/Training_821...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9821</th>\n",
       "      <td>Datasets/RAF-FER-SFEW/train/fear/Training_8809...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                filepath     label\n",
       "22457  Datasets/RAF-FER-SFEW/train/disgust/train_0543...   disgust\n",
       "44080  Datasets/RAF-FER-SFEW/train/happy/train_03946_...     happy\n",
       "5516   Datasets/RAF-FER-SFEW/test/happy/PrivateTest_6...     happy\n",
       "48241  Datasets/RAF-FER-SFEW/train/angry/Training_161...     angry\n",
       "48214  Datasets/RAF-FER-SFEW/train/neutral/Training_9...   neutral\n",
       "44811  Datasets/RAF-FER-SFEW/test/happy/PublicTest_14...     happy\n",
       "45062  Datasets/RAF-FER-SFEW/train/surprise/Training_...  surprise\n",
       "5300   Datasets/RAF-FER-SFEW/train/fear/Training_3563...      fear\n",
       "26121  Datasets/RAF-FER-SFEW/test/happy/test_1143_ali...     happy\n",
       "16031  Datasets/RAF-FER-SFEW/test/angry/PublicTest_38...     angry\n",
       "5321   Datasets/RAF-FER-SFEW/train/happy/Training_107...     happy\n",
       "44126  Datasets/RAF-FER-SFEW/train/happy/Training_365...     happy\n",
       "31241  Datasets/RAF-FER-SFEW/train/angry/Training_238...     angry\n",
       "30017  Datasets/RAF-FER-SFEW/train/happy/Training_821...     happy\n",
       "9821   Datasets/RAF-FER-SFEW/train/fear/Training_8809...      fear"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to your training and testing directories\n",
    "train_dir = 'Datasets/RAF-FER-SFEW/train'  # Replace with your training directory path\n",
    "test_dir = 'Datasets/RAF-FER-SFEW/test'    # Replace with your testing directory path\n",
    "\n",
    "# Function to add images from a directory to a list\n",
    "def process_directory(directory, data_list):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Loop through each image in the folder\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                # Append to the data list\n",
    "                data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "# Initialize an empty list for storing data\n",
    "data_list = []\n",
    "\n",
    "# Add training images to the data list\n",
    "process_directory(train_dir, data_list)\n",
    "\n",
    "# Add testing images to the data list\n",
    "process_directory(test_dir, data_list)\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# print 15 random samples of the DataFrame\n",
    "df.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 52490\n",
      "Training set: 0.60 (31494 samples)\n",
      "Validation set: 0.20 (10498 samples)\n",
      "Test set: 0.20 (10498 samples)\n",
      "\n",
      "Found 31494 validated image filenames belonging to 7 classes.\n",
      "Found 10498 validated image filenames belonging to 7 classes.\n",
      "Found 10498 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your training and testing directories\n",
    "# train_dir = 'Datasets/RAF-DB/DATASET/train'\n",
    "# test_dir = 'Datasets/RAF-DB/DATASET/test'\n",
    "# train_dir = 'Datasets/FER2013/train'\n",
    "# test_dir = 'Datasets/FER2013/test'\n",
    "# Set the image size and batch size\n",
    "image_size = (96, 96) # Can be increased to improve accuracy or decreased to improve speed. (48, 48) for FER2013, (224, 224) for RAF-DB\n",
    "batch_size = 64\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)  # 80% training, 20% test\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)  # Of the 80% training, split into 60% training and 20% validation\n",
    "\n",
    "# Calculate and print split ratios\n",
    "total_samples = len(df)\n",
    "train_ratio = len(train_df) / total_samples\n",
    "val_ratio = len(val_df) / total_samples\n",
    "test_ratio = len(test_df) / total_samples\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Training set: {train_ratio:.2f} ({len(train_df)} samples)\")\n",
    "print(f\"Validation set: {val_ratio:.2f} ({len(val_df)} samples)\")\n",
    "print(f\"Test set: {test_ratio:.2f} ({len(test_df)} samples)\\n\")\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation (optional)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values to [0, 1]\n",
    "    rotation_range=15,  # rotation\n",
    "    width_shift_range=0.05, # horizontal shift (only 5% since faces are centered)\n",
    "    height_shift_range=0.05, # vertical shift (only 5% since faces are centered)\n",
    "    shear_range=0.1, \n",
    "    # zoom_range=0.1,   zoom (with current dataset not needed, since faces are centered)\n",
    "    horizontal_flip=True, # flip images horizontally\n",
    "    fill_mode='constant', # fill in missing pixels (nearest / constant)\n",
    "    # brightness_range=[0.8, 1.2] # darken and lighten images\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for validation data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for test data\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',\n",
    "#     classes=np.unique(train_generator.classes),\n",
    "#     y=train_generator.classes\n",
    "# )\n",
    "# \n",
    "# class_weights_dict = dict(enumerate(class_weights))\n",
    "# print(class_weights_dict)\n",
    "\n",
    "# # Compute class weights\n",
    "# labels = train_df['label'].values\n",
    "# unique_classes = np.unique(labels)\n",
    "# class_weights = compute_class_weight('balanced', classes=unique_classes, y=labels)\n",
    "# class_weights_dict = {unique_classes[i]: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Assuming 'labels' contains your class labels for the training data\n",
    "labels = train_df['label'].values\n",
    "unique_classes = np.unique(labels)\n",
    "# Compute class weights for balanced training\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=labels)\n",
    "# Get class indices from the generator\n",
    "class_indices = train_generator.class_indices\n",
    "# Ensure the order of `unique_classes` matches the order in `class_indices`\n",
    "ordered_unique_classes = sorted(unique_classes, key=lambda x: class_indices[x])\n",
    "# Create a dictionary mapping class indices to their weights\n",
    "class_weights_dict = {class_indices[label]: weight for label, weight in zip(ordered_unique_classes, class_weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 41839 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create a non-preprocessing ImageDataGenerator\n",
    "no_preprocessing_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create a temporary generator to fetch a batch of original images\n",
    "temp_generator = no_preprocessing_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Keep the same order as the original generator\n",
    ")\n",
    "\n",
    "# Function to plot images in a grid\n",
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img.astype('uint8'))  # Cast to uint8 for correct image display\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a batch of original images\n",
    "original_batch = next(temp_generator)\n",
    "original_images = original_batch[0][:25]  # Select first 25 images\n",
    "\n",
    "# Plot the original images\n",
    "# plot_images(original_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot images in a grid\n",
    "def plot_images(images_arr):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img, cmap='gray')  # Set the colormap to 'gray'\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images\n",
    "example_batch = next(train_generator)\n",
    "example_images = example_batch[0][:25]  # Select first 25 imaages\n",
    "\n",
    "# Plot the images\n",
    "# plot_images(example_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 94, 94, 256)       2560      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 47, 47, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 47, 47, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 45, 45, 128)       295040    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 22, 22, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 20, 20, 128)       147584    \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20, 20, 128)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 18, 18, 128)       147584    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 592768 (2.26 MB)\n",
      "Trainable params: 592768 (2.26 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dropProb=0.0 # fraction of units to drop\n",
    "nfilter_1 = 256\n",
    "nfilter_2 = 128\n",
    "nfilter_3 = 128\n",
    "nfilter_4 = 64\n",
    "nhid=64\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(filters=nfilter_1, kernel_size=(3, 3), \n",
    "                        activation='relu', input_shape=(96, 96, 1)))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(rate=dropProb))\n",
    "model.add(layers.Conv2D(filters=nfilter_2, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Dropout(rate=dropProb))\n",
    "model.add(layers.Conv2D(filters=nfilter_3, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(rate=dropProb))\n",
    "model.add(layers.Conv2D(filters=nfilter_3, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting. This stops training when the model's performance on the validation set starts to degrade.\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to be monitored\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped. Reduced from 10\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "checkpoint = ModelCheckpoint(\n",
    "    'model_checkpoint.keras',  # Path where to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=False,    # Save only the best model. Set False to save the model at the end of every epoch so restarting from specific epoch is possible\n",
    "    save_weights_only=False, # Save only the weights\n",
    "    mode='min',             # Minimize the monitored metric (val_loss) min before\n",
    "    verbose=1               # Verbose output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the last saved weights\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.load_weights('model_checkpoint.keras')\u001b[39;00m\n\u001b[1;32m      4\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;66;03m# When resuming training, set epochs to the total number of epochs you want to train, not just the additional epochs. The model.fit() method continues training for the specified number of epochs, starting from the current epoch count. Typically, 10 to 100 epochs are used. Start with e.g. 30-50.\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mval_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weights_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Save the training history for later analysis\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_history.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/FER/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.pyenv/versions/3.11.7/envs/FER/lib/python3.11/site-packages/keras/src/engine/training.py:3983\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3977\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_assert_compile_was_called\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   3978\u001b[0m     \u001b[38;5;66;03m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3980\u001b[0m     \u001b[38;5;66;03m# model is compiled\u001b[39;00m\n\u001b[1;32m   3981\u001b[0m     \u001b[38;5;66;03m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3982\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3984\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must compile your model before \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3985\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining/testing. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3986\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3987\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "# Load the last saved weights\n",
    "#model.load_weights('model_checkpoint.keras')\n",
    "\n",
    "epochs = 30 # When resuming training, set epochs to the total number of epochs you want to train, not just the additional epochs. The model.fit() method continues training for the specified number of epochs, starting from the current epoch count. Typically, 10 to 100 epochs are used. Start with e.g. 30-50.\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopper, checkpoint]\n",
    ")\n",
    "\n",
    "# Save the training history for later analysis\n",
    "with open('training_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 31494 validated image filenames belonging to 7 classes.\n",
      "Found 10498 validated image filenames belonging to 7 classes.\n",
      "Found 10498 validated image filenames belonging to 7 classes.\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_15 (Conv2D)          (None, 94, 94, 64)        640       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPoolin  (None, 47, 47, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 47, 47, 64)        0         \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 45, 45, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 22, 22, 128)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 22, 22, 128)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 20, 20, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPooli  (None, 10, 10, 256)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 10, 10, 256)       0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                1638464   \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 455       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2008583 (7.66 MB)\n",
      "Trainable params: 2008583 (7.66 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      "492/492 [==============================] - 100s 202ms/step - loss: 1.9498 - accuracy: 0.1369 - val_loss: 1.9374 - val_accuracy: 0.1841\n",
      "Epoch 2/3\n",
      "492/492 [==============================] - 100s 203ms/step - loss: 1.9167 - accuracy: 0.1915 - val_loss: 1.8477 - val_accuracy: 0.2839\n",
      "Epoch 3/3\n",
      "492/492 [==============================] - 102s 208ms/step - loss: 1.8510 - accuracy: 0.2086 - val_loss: 1.7933 - val_accuracy: 0.2510\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to your training and testing directories\n",
    "train_dir = 'Datasets/RAF-FER-SFEW/train'\n",
    "test_dir = 'Datasets/RAF-FER-SFEW/test'\n",
    "\n",
    "# Function to add images from a directory to a list\n",
    "def process_directory(directory, data_list):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "data_list = []\n",
    "process_directory(train_dir, data_list)\n",
    "process_directory(test_dir, data_list)\n",
    "df = pd.DataFrame(data_list)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "image_size = (96, 96)\n",
    "batch_size = 64\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant',\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "labels = train_df['label'].values\n",
    "unique_classes = np.unique(labels)\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=labels)\n",
    "class_indices = train_generator.class_indices\n",
    "ordered_unique_classes = sorted(unique_classes, key=lambda x: class_indices[x])\n",
    "class_weights_dict = {class_indices[label]: weight for label, weight in zip(ordered_unique_classes, class_weights)}\n",
    "\n",
    "# Model Definition\n",
    "dropProb = 0.5  # Adjust dropout rate as needed\n",
    "nfilter_1 = 64\n",
    "nfilter_2 = 128\n",
    "nfilter_3 = 256\n",
    "nfilter_4 = 512\n",
    "nhid = 64\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(nfilter_1, (3, 3), activation='relu', input_shape=(96, 96, 1)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(dropProb),\n",
    "    Conv2D(nfilter_2, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(dropProb),\n",
    "    Conv2D(nfilter_3, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Dropout(dropProb),\n",
    "    Flatten(),\n",
    "    Dense(nhid, activation='relu'),\n",
    "    Dropout(dropProb),\n",
    "    Dense(len(unique_classes), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Callbacks\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('model_checkpoint.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "epochs = 3\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopper, checkpoint]\n",
    ")\n",
    "\n",
    "# Save history\n",
    "with open('training_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6282 validated image filenames belonging to 7 classes.\n",
      "Found 2095 validated image filenames belonging to 7 classes.\n",
      "Found 2095 validated image filenames belonging to 7 classes.\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_96_no_top.h5\n",
      "9406464/9406464 [==============================] - 1s 0us/step\n",
      "Epoch 1/30\n",
      "196/196 [==============================] - 10s 46ms/step - loss: 1.9677 - accuracy: 0.2661 - val_loss: 1.7489 - val_accuracy: 0.3072 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.7304 - accuracy: 0.3162 - val_loss: 1.6840 - val_accuracy: 0.3322 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.6991 - accuracy: 0.3253 - val_loss: 1.6768 - val_accuracy: 0.3332 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.6793 - accuracy: 0.3392 - val_loss: 1.6569 - val_accuracy: 0.3322 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "196/196 [==============================] - 10s 48ms/step - loss: 1.6597 - accuracy: 0.3390 - val_loss: 1.7115 - val_accuracy: 0.3163 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.6461 - accuracy: 0.3506 - val_loss: 1.6649 - val_accuracy: 0.3341 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.6325 - accuracy: 0.3542 - val_loss: 1.6387 - val_accuracy: 0.3466 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "196/196 [==============================] - 10s 50ms/step - loss: 1.6343 - accuracy: 0.3579 - val_loss: 1.6488 - val_accuracy: 0.3466 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "196/196 [==============================] - 10s 51ms/step - loss: 1.6179 - accuracy: 0.3562 - val_loss: 1.6279 - val_accuracy: 0.3471 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "196/196 [==============================] - 10s 50ms/step - loss: 1.6070 - accuracy: 0.3669 - val_loss: 1.5918 - val_accuracy: 0.3740 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.6023 - accuracy: 0.3731 - val_loss: 1.6518 - val_accuracy: 0.3423 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.5941 - accuracy: 0.3710 - val_loss: 1.6317 - val_accuracy: 0.3433 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.5775 - accuracy: 0.3843 - val_loss: 1.6231 - val_accuracy: 0.3510 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.5710 - accuracy: 0.3920 - val_loss: 1.6157 - val_accuracy: 0.3659 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "196/196 [==============================] - 10s 48ms/step - loss: 1.5521 - accuracy: 0.3870 - val_loss: 1.5995 - val_accuracy: 0.3707 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.5489 - accuracy: 0.3914 - val_loss: 1.6495 - val_accuracy: 0.3428 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "196/196 [==============================] - 9s 47ms/step - loss: 1.5519 - accuracy: 0.3890 - val_loss: 1.6224 - val_accuracy: 0.3615 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "196/196 [==============================] - 9s 48ms/step - loss: 1.5382 - accuracy: 0.4045 - val_loss: 1.6444 - val_accuracy: 0.3476 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "196/196 [==============================] - 10s 50ms/step - loss: 1.5497 - accuracy: 0.3933 - val_loss: 1.6127 - val_accuracy: 0.3611 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "196/196 [==============================] - 36s 183ms/step - loss: 1.5378 - accuracy: 0.3962 - val_loss: 1.6025 - val_accuracy: 0.3692 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define paths to your training and testing directories\n",
    "train_dir = 'Datasets/RAF-FER-SFEW/train'\n",
    "test_dir = 'Datasets/RAF-FER-SFEW/test'\n",
    "\n",
    "def process_directory(directory, data_list):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "data_list = []\n",
    "process_directory(train_dir, data_list)\n",
    "process_directory(test_dir, data_list)\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "min_count = df['label'].value_counts().min()\n",
    "balanced_df = pd.concat([\n",
    "    df[df['label'] == label].sample(min_count, random_state=42) for label in df['label'].unique()\n",
    "])\n",
    "balanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "image_size = (96, 96)\n",
    "batch_size = 32\n",
    "\n",
    "train_df, test_df = train_test_split(balanced_df, test_size=0.2, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.25, random_state=42)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df, x_col='filepath', y_col='label',\n",
    "                                                    target_size=image_size, batch_size=batch_size,\n",
    "                                                    color_mode='rgb', class_mode='categorical')\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(val_df, x_col='filepath', y_col='label',\n",
    "                                                target_size=image_size, batch_size=batch_size,\n",
    "                                                color_mode='rgb', class_mode='categorical')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df, x_col='filepath', y_col='label',\n",
    "                                                  target_size=image_size, batch_size=batch_size,\n",
    "                                                  color_mode='rgb', class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Transfer Learning with MobileNetV2\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(96, 96, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(1024, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "early_stopper = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "checkpoint = ModelCheckpoint('model_checkpoint.keras', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
    "\n",
    "# Training\n",
    "epochs = 30\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // batch_size,\n",
    "    callbacks=[early_stopper, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save training history\n",
    "with open('training_history.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
