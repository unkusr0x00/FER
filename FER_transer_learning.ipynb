{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "70c53135883349b6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Preperation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ef29535ba1ea78c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define paths to your training and testing directories\n",
    "data_dir = 'Datasets/combined_dataset_processed_224_3'\n",
    "\n",
    "# Function to add images from a directory to a list\n",
    "def process_directory(directory, data_list):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Loop through each image in the folder\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                # For test purposes use only processed images that DeepFace classifies correctly\n",
    "                # processed_image_path = image_path.replace('combined_dataset_deepface', 'combined_dataset_processed')\n",
    "                # Append to the data list\n",
    "                data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "# Initialize an empty list for storing data\n",
    "data_list = []\n",
    "# Add training images to the data list\n",
    "process_directory(data_dir, data_list)\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# Print the amount of images per category before balancing\n",
    "print(\"Images per category:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, temp_test_val_df = train_test_split(df, train_size=0.7, random_state=42)\n",
    "test_df, val_df = train_test_split(temp_test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Balance the test and validation sets\n",
    "# Determine the smallest class size within each of the test and validation sets\n",
    "min_test_class_size = test_df['label'].value_counts().min()\n",
    "min_val_class_size = val_df['label'].value_counts().min()\n",
    "\n",
    "# Determine the smallest size between the two for a uniform approach\n",
    "uniform_min_size = min(min_test_class_size, min_val_class_size)\n",
    "\n",
    "# Function to reduce class sizes\n",
    "def balance_classes(df, target_size):\n",
    "    balanced_df = pd.DataFrame()  # Initialize an empty DataFrame to hold the balanced data\n",
    "    for label in df['label'].unique():\n",
    "        subset = df[df['label'] == label].sample(n=target_size, random_state=42)\n",
    "        balanced_df = pd.concat([balanced_df, subset])\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing\n",
    "test_df = balance_classes(test_df, uniform_min_size)\n",
    "val_df = balance_classes(val_df, uniform_min_size)\n",
    "\n",
    "# Calculate and print split ratios\n",
    "total_samples = len(df)\n",
    "train_ratio = len(train_df) / total_samples\n",
    "val_ratio = len(val_df) / total_samples\n",
    "test_ratio = len(test_df) / total_samples\n",
    "\n",
    "print(f\"\\nTotal samples: {total_samples}\")\n",
    "print(f\"Training set: {train_ratio:.2f} ({len(train_df)} samples)\")\n",
    "print(f\"Validation set: {val_ratio:.2f} ({len(val_df)} samples)\")\n",
    "print(f\"Test set: {test_ratio:.2f} ({len(test_df)} samples)\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1f5334881d4c531b",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b073617df919cb24"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the image size and batch size\n",
    "image_size = (224, 224) # Can be increased to improve accuracy or decreased to improve speed. (48, 48) for FER2013, (224, 224) for RAF-DB\n",
    "batch_size = 64\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation (optional)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values to [0, 1]\n",
    "    # rotation_range=15,  # rotation. Not needed since all images are getting aligned\n",
    "    width_shift_range=0.05, # horizontal shift (only 5% since faces are centered)\n",
    "    height_shift_range=0.05, # vertical shift (only 5% since faces are centered)\n",
    "    shear_range=0.1, \n",
    "    # zoom_range=0.1,   zoom (with current dataset not needed, since faces are centered)\n",
    "    horizontal_flip=True, # flip images horizontally\n",
    "    fill_mode='constant', # fill in missing pixels (nearest / constant)\n",
    "    # brightness_range=[0.8, 1.2] # darken and lighten images\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for validation data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for test data\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "# Assuming 'labels' contains your class labels for the training data\n",
    "labels = train_df['label'].values\n",
    "unique_classes = np.unique(labels)\n",
    "# Compute class weights for balanced training\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=labels)\n",
    "# Get class indices from the generator\n",
    "class_indices = train_generator.class_indices\n",
    "# Ensure the order of `unique_classes` matches the order in `class_indices`\n",
    "ordered_unique_classes = sorted(unique_classes, key=lambda x: class_indices[x])\n",
    "# Create a dictionary mapping class indices to their weights\n",
    "class_weights_dict = {class_indices[label]: weight for label, weight in zip(ordered_unique_classes, class_weights)}\n",
    "print(class_weights_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d7ee56fed5820668",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image before and after preprocessing comparison"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f615bc102271c24d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a non-preprocessing ImageDataGenerator\n",
    "no_preprocessing_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create a temporary generator to fetch a batch of original images\n",
    "temp_generator = no_preprocessing_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True  # Keep the same order as the original generator\n",
    ")\n",
    "\n",
    "# Function to plot images in a grid\n",
    "def plot_images_before(images_arr):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img.astype('uint8'))  # Cast to uint8 for correct image display\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a batch of original images\n",
    "original_batch = next(temp_generator)\n",
    "original_images = original_batch[0][:25]  # Select first 25 images\n",
    "\n",
    "# Function to plot images in a grid\n",
    "def plot_images_after(images_arr):\n",
    "    fig, axes = plt.subplots(5, 5, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img, cmap='gray')  # Set the colormap to 'gray'\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images\n",
    "example_batch = next(train_generator)\n",
    "example_images = example_batch[0][:25]  # Select first 25 images\n",
    "\n",
    "# Plot the images\n",
    "# plot_images_before(original_images)\n",
    "# plot_images_after(example_images)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95093d13124afc68",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ResNet50V2\n",
    "ResNet50V2 expects 224x224 input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5f0e87c4c753dae"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the ResNet50V2 model\n",
    "base_model = ResNet50V2(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Create the final model\n",
    "model_resnet50v2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model_resnet50v2.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model_resnet50v2.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171161274f2f0ad9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## VGG-16"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3ad6c09d6aaa90e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the VGG16 model\n",
    "base_model = VGG16(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# Freeze the layers except the last 4 layers\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for FER\n",
    "x = base_model.output\n",
    "x = Flatten()(x)  # Flatten the output layer to 1 dimension\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Add batch normalization\n",
    "x = Dropout(0.5)(x)  # Add dropout\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Add batch normalization\n",
    "x = Dropout(0.5)(x)  # Add dropout\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Compile the model\n",
    "model_vgg16 = Model(inputs=base_model.input, outputs=predictions)\n",
    "model_vgg16.compile(optimizer=Adam(learning_rate=0.003), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_vgg16.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6e85d001eba74b72",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## MobileNetV2"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "121579ddefffe490"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the MobileNetV2\n",
    "base_model = MobileNetV2(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5')\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for FER\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Add batch normalization\n",
    "x = Dropout(0.5)(x)  # Add dropout to prevent overfitting\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Compile the model\n",
    "model_mobilenetv2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "model_mobilenetv2.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_mobilenetv2.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3070dac92184e356"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EfficientNetB0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e0125d2bf2bd908"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the EfficientNetB0 model\n",
    "base_model = EfficientNetB0(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/efficientnetb0_notop.h5')\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for FER\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Add batch normalization\n",
    "x = Dropout(0.5)(x)  # Add dropout\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Compile the model\n",
    "model_efficientnetb0 = Model(inputs=base_model.input, outputs=predictions)\n",
    "model_efficientnetb0.compile(optimizer=SGD(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_efficientnetb0.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4cecf5238d826b96"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DenseNet121"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc53f2879911631e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the DenseNet121\n",
    "base_model = DenseNet121(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers[:-4]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers for FER\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)  # Add batch normalization\n",
    "x = Dropout(0.5)(x)  # Add dropout to prevent overfitting\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Compile the model\n",
    "model_densenet121 = Model(inputs=base_model.input, outputs=predictions)\n",
    "model_densenet121.compile(optimizer=Adam(learning_rate=0.0002), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model_densenet121.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d08e15f2d6946a27"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57277d0c8f3d9929"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting. This stops training when the model's performance on the validation set starts to degrade.\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to be monitored\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    f'logs/model_checkpoint_vgg16_{timestamp}.keras',  # Path where to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=False,    # Save only the best model. Set False to save the model at the end of every epoch so restarting from specific epoch is possible\n",
    "    save_weights_only=False, # Save only the weights\n",
    "    mode='min',             # Minimize the monitored metric (val_loss) min before\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=0.0001,\n",
    "    cooldown=3,\n",
    "    verbose=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b831e87eaf7c2fc1",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90839989bd8e9f83"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Choose from: model_resnet50v2, model_vgg16, model_mobilenetv2, model_efficientnetb0, model_densenet121\n",
    "model = model_vgg16\n",
    "epochs = 30  # When resuming training, set epochs to the total number of epochs you want to train, not just the additional epochs. The model.fit() method continues training for the specified number of epochs, starting from the current epoch count.\n",
    "\n",
    "# Load the last saved weights\n",
    "model.load_weights('logs/model_checkpoint_vgg16.keras')\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopper, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the training history for later analysis\n",
    "with open(f'logs/training_history_vgg16_{timestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e96884339fd1e54a",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation and Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d4ff75949a185bc"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "test_generator.reset() # Ensuring the generator is reset to the beginning\n",
    "predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "predicted_classes = np.argmax(predictions, axis=1) # Convert predictions to class labels\n",
    "\n",
    "# Since the generator omits some samples due to rounding down in 'steps',  trim 'true_classes' to match 'predicted_classes' length\n",
    "true_classes = test_generator.classes\n",
    "true_classes = true_classes[:len(predicted_classes)]\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "\n",
    "# Additional weighted metric calculations\n",
    "weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "print(\"Weighted Precision:\", weighted_precision)\n",
    "print(\"Weighted Recall:\", weighted_recall)\n",
    "print(\"Weighted F1-Score:\", weighted_f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6d075448cf745db"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "150e1cdfada6b7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conducting error analysis\n",
    "This can be done by examining misclassified examples, which can provide insights into what types of errors the model is making"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3713fda8f6ff828"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Learning Curves\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c2c6cee8c1b3ae9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Precsion-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels for multi-class\n",
    "y_bin = label_binarize(true_classes, classes=np.arange(len(class_labels)))\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Compute precision-recall curve for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], predictions[:, i])\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='Class {}'.format(class_labels[i]))\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Precision vs. Recall curve\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a43515a62c28b6ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ROC Curve and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Class {} (area = {:.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d62874db97b32189"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "94ea22bfd610fdf7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
