{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, \\\n",
    "    concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.utils import to_categorical"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e50fd6acbccbdee4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Date preperation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fa317361b0a45ef8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def process_directory(directory, data_list, file_type):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Loop through each image in the folder\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                if file_type == 'jpg' and image_name.endswith('.jpg'):\n",
    "                    image_path = os.path.join(class_dir, image_name)\n",
    "                    data_list.append({'filepath': image_path, 'label': class_name})\n",
    "                elif file_type == 'npy' and image_name.endswith('.npy'):\n",
    "                    image_path = os.path.join(class_dir, image_name)\n",
    "                    image = np.load(image_path)\n",
    "                    # Check if the image is of size 128x128 with 8 channels\n",
    "                    if image.shape == (128, 128, 8):\n",
    "                        data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "# Initialize an empty list for storing data\n",
    "data_list = []\n",
    "\n",
    "# Define paths to your training and testing directories for jpg and npy files\n",
    "data_dir_jpg = 'Datasets/combined_dataset_processed_128_1'\n",
    "data_dir_npy = 'Datasets/combined_dataset_enhanced_npy_6_channels'\n",
    "\n",
    "# Add training images to the data list for jpg and npy files\n",
    "process_directory(data_dir_jpg, data_list, 'jpg')\n",
    "process_directory(data_dir_npy, data_list, 'npy')\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Print the amount of images per category before balancing\n",
    "print(\"Images per category:\")\n",
    "print(df['label'].value_counts())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "97e167629e971abc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cda7a9be4cfee36d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "image_size = (128, 128)\n",
    "batch_size = 32  # Choose a unified batch size that works well for both datasets\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.1, random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.11, random_state=42)\n",
    "\n",
    "# Calculate and print split ratios\n",
    "total_samples = len(df)\n",
    "train_ratio = len(train_df) / total_samples\n",
    "val_ratio = len(val_df) / total_samples\n",
    "test_ratio = len(test_df) / total_samples\n",
    "\n",
    "print(f\"Total samples: {total_samples}\")\n",
    "print(f\"Training set: {train_ratio:.2f} ({len(train_df)} samples)\")\n",
    "print(f\"Validation set: {val_ratio:.2f} ({len(val_df)} samples)\")\n",
    "print(f\"Test set: {test_ratio:.2f} ({len(test_df)} samples)\\n\")\n",
    "\n",
    "\n",
    "# Encode labels to integers for .npy data handling\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n",
    "val_df['encoded_label'] = label_encoder.transform(val_df['label'])\n",
    "test_df['encoded_label'] = label_encoder.transform(test_df['label'])\n",
    "\n",
    "# Image Data Generators for JPEG images\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values to [0, 1]\n",
    "    # rotation_range=15,  # rotation. Not needed since all images are getting aligned\n",
    "    width_shift_range=0.05, # horizontal shift (only 5% since faces are centered)\n",
    "    height_shift_range=0.05, # vertical shift (only 5% since faces are centered)\n",
    "    shear_range=0.1, \n",
    "    # zoom_range=0.1,   zoom (with current dataset not needed, since faces are centered)\n",
    "    horizontal_flip=True, # flip images horizontally\n",
    "    fill_mode='constant', # fill in missing pixels (nearest / constant)\n",
    "    # brightness_range=[0.8, 1.2] # darken and lighten images\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Prepare Image Generators\n",
    "train_generator = train_datagen.flow_from_dataframe(train_df[train_df['filepath'].str.contains('.jpg')], x_col='filepath', y_col='label', target_size=image_size, batch_size=batch_size, color_mode='grayscale', class_mode='categorical')\n",
    "val_generator = val_datagen.flow_from_dataframe(val_df[val_df['filepath'].str.contains('.jpg')], x_col='filepath', y_col='label', target_size=image_size, batch_size=batch_size, color_mode='grayscale', class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_dataframe(test_df[test_df['filepath'].str.contains('.jpg')], x_col='filepath', y_col='label', target_size=image_size, batch_size=batch_size, color_mode='grayscale', class_mode='categorical', shuffle=False)\n",
    "\n",
    "def set_shapes(img, label, img_shape=(128, 128, 8), label_shape=(7, )):\n",
    "    img.set_shape(img_shape)\n",
    "    label.set_shape(label_shape)\n",
    "    return img, label\n",
    "\n",
    "# Function to preprocess .npy files\n",
    "def preprocess_npy(file_path, label):\n",
    "    image = np.load(file_path.numpy())\n",
    "    image = image.astype(np.float32) / 255.0\n",
    "    label = to_categorical(label, num_classes=7) \n",
    "    return image, label\n",
    "\n",
    "# TensorFlow Dataset for .npy files\n",
    "def create_dataset(df):\n",
    "    df_npy = df[df['filepath'].str.contains('.npy')]\n",
    "    file_paths = df_npy['filepath'].values\n",
    "    labels = df_npy['encoded_label'].values\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((file_paths, labels))\n",
    "    dataset = dataset.map(lambda x, y: tf.py_function(preprocess_npy, [x, y], [tf.float32, tf.float32]), num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    #dataset = dataset.map(set_shapes)\n",
    "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_dataset = create_dataset(train_df)\n",
    "val_dataset = create_dataset(val_df)\n",
    "test_dataset = create_dataset(test_df)\n",
    "\n",
    "labels = df['label'].values\n",
    "# Determine unique classes and their corresponding frequencies\n",
    "classes, frequencies = np.unique(labels, return_counts=True)\n",
    "# Calculate class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=labels)\n",
    "# Map the calculated weights to their corresponding class labels\n",
    "class_weight_dict = {class_label: weight for class_label, weight in zip(classes, class_weights)}\n",
    "print(class_weight_dict)\n",
    "\n",
    "for images, labels in train_dataset.take(1):  # Take a single batch from the dataset\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "468937f4089725e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a780f146fbd642a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Input shapes\n",
    "input_shape_plain = (128, 128, 1)  # For grayscale images\n",
    "input_shape_npy = (128, 128, 8)    # For .npy files with 8 channels\n",
    "\n",
    "# Model configuration\n",
    "l2_reg = 0.001\n",
    "dropout_rates = [0.15, 0.5]\n",
    "n_filters = [128, 64, 64, 32, 32, 128]\n",
    "\n",
    "# Define two sets of inputs\n",
    "input_plain = Input(shape=input_shape_plain, name='grayscale_input')\n",
    "input_npy = Input(shape=input_shape_npy, name='npy_input')\n",
    "\n",
    "# Grayscale image branch\n",
    "x1 = Conv2D(n_filters[0], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(input_plain)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Dropout(dropout_rates[0])(x1)\n",
    "\n",
    "x1 = Conv2D(n_filters[1], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Dropout(dropout_rates[0])(x1)\n",
    "\n",
    "x1 = Conv2D(n_filters[3], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x1)\n",
    "x1 = BatchNormalization()(x1)\n",
    "x1 = MaxPooling2D(pool_size=(2, 2))(x1)\n",
    "x1 = Dropout(dropout_rates[0])(x1)\n",
    "\n",
    "x1 = Flatten()(x1)\n",
    "\n",
    "# .npy files branch\n",
    "x2 = Conv2D(n_filters[0], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(input_npy)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x2 = Dropout(dropout_rates[0])(x2)\n",
    "\n",
    "x2 = Conv2D(n_filters[1], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x2 = Dropout(dropout_rates[0])(x2)\n",
    "\n",
    "x2 = Conv2D(n_filters[3], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg))(x2)\n",
    "x2 = BatchNormalization()(x2)\n",
    "x2 = MaxPooling2D(pool_size=(2, 2))(x2)\n",
    "x2 = Dropout(dropout_rates[0])(x2)\n",
    "\n",
    "x2 = Flatten()(x2)\n",
    "\n",
    "# Merge the outputs of the two branches\n",
    "combined = concatenate([x1, x2])\n",
    "\n",
    "# Fully connected layers\n",
    "z = Dense(n_filters[5], activation='relu', kernel_regularizer=l2(l2_reg))(combined)\n",
    "z = BatchNormalization()(z)\n",
    "z = Dropout(dropout_rates[1])(z)\n",
    "z = Dense(7, activation='softmax', kernel_regularizer=l2(l2_reg))(z)  # Assuming 7 classes for output\n",
    "\n",
    "# Final model\n",
    "model = Model(inputs=[input_plain, input_npy], outputs=z)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary to verify the architecture\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "436ea135ad053d03"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "252f91f2882b8936"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting. This stops training when the model's performance on the validation set starts to degrade.\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to be monitored\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped. Reduced from 10\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    f'logs/model_checkpoint_{timestamp}.keras',  # Path where to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=False,    # Save only the best model. Set False to save the model at the end of every epoch so restarting from specific epoch is possible\n",
    "    save_weights_only=False, # Save only the weights\n",
    "    mode='min',             # Minimize the monitored metric (val_loss) min before\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=0.0001,\n",
    "    cooldown=3,\n",
    "    verbose=1,\n",
    "    mode='min'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ec76f80bd940a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c9be1a4d702f63d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Custom Data Generator to merge JPEG and NPY datasets\n",
    "class CustomDataGenerator(Sequence):\n",
    "    def __init__(self, df_jpg, df_npy, batch_size, image_size, label_encoder, for_training=True):\n",
    "        self.df_jpg = df_jpg\n",
    "        self.df_npy = df_npy\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.label_encoder = label_encoder\n",
    "        self.for_training = for_training\n",
    "\n",
    "        # ImageDataGenerator for real-time data augmentation\n",
    "        self.datagen = ImageDataGenerator(rescale=1./255) if for_training else ImageDataGenerator(rescale=1./255)\n",
    "        \n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Use the larger of the two datasets to determine the number of steps\n",
    "        return max(len(self.df_jpg), len(self.df_npy)) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if index % 2 == 0:\n",
    "            # Process JPEG images\n",
    "            batch_df = self.df_jpg[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "            x_batch = np.zeros((len(batch_df), *self.image_size, 1), dtype='float32')\n",
    "            for i, row in enumerate(batch_df.itertuples()):\n",
    "                img_path = row.filepath\n",
    "                img = tf.keras.preprocessing.image.load_img(img_path, color_mode='grayscale', target_size=self.image_size)\n",
    "                img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "                x_batch[i] = img_array\n",
    "            \n",
    "            y_batch = self.label_encoder.transform(batch_df['label'].values)\n",
    "            y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=7)  # Adjust based on the number of classes\n",
    "        else:\n",
    "            # Process NPY files\n",
    "            batch_df = self.df_npy[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "            x_batch = np.array([np.load(row.filepath) for row in batch_df.itertuples()])\n",
    "            y_batch = self.label_encoder.transform(batch_df['label'].values)\n",
    "            y_batch = tf.keras.utils.to_categorical(y_batch, num_classes=7)  # Adjust based on the number of classes\n",
    "        \n",
    "        # Apply data augmentation on-the-fly for JPEG images (if for_training is True)\n",
    "        if self.for_training and index % 2 == 0:\n",
    "            x_batch = np.array([self.datagen.random_transform(img) for img in x_batch])\n",
    "        \n",
    "        return x_batch, y_batch\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.for_training:\n",
    "            # Shuffle the dataset (for training only)\n",
    "            self.df_jpg = self.df_jpg.sample(frac=1).reset_index(drop=True)\n",
    "            self.df_npy = self.df_npy.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "labels = df['label'].values\n",
    "label_encoder.fit(labels)\n",
    "\n",
    "class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "\n",
    "# Prepare CustomDataGenerators for training and validation\n",
    "train_generator = CustomDataGenerator(train_df[train_df['filepath'].str.contains('.jpg')],\n",
    "                                      train_df[train_df['filepath'].str.contains('.npy')],\n",
    "                                      batch_size,\n",
    "                                      image_size,\n",
    "                                      label_encoder,\n",
    "                                      for_training=True)\n",
    "val_generator = CustomDataGenerator(val_df[val_df['filepath'].str.contains('.jpg')],\n",
    "                                    val_df[val_df['filepath'].str.contains('.npy')],\n",
    "                                    batch_size,\n",
    "                                    image_size,\n",
    "                                    label_encoder,\n",
    "                                    for_training=False)\n",
    "\n",
    "# Unified model.fit() call\n",
    "# history = model.fit(train_generator,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=val_generator,\n",
    "#                     class_weight=class_weight_dict,\n",
    "#                     verbose=1)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=val_generator,\n",
    "                    class_weight=class_weight_dict,\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list,\n",
    "                    steps_per_epoch=len(train_generator),  # Defined by __len__ in CustomDataGenerator\n",
    "                    validation_steps=len(val_generator))   # Defined by __len__ in CustomDataGenerator"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c1d1afaf111d894a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the last saved weights\n",
    "# model.load_weights('logs/model_checkpoint_20240225_085054.keras')\n",
    "\n",
    "epochs = 30 # When resuming training, set epochs to the total number of epochs you want to train, not just the additional epochs. The model.fit() method continues training for the specified number of epochs, starting from the current epoch count.\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    class_weight=class_weights_dict\n",
    "    # callbacks=[early_stopper, checkpoint]\n",
    ")\n",
    "\n",
    "history_lm = model.fit(\n",
    "    train_dataset,  # Training data\n",
    "    epochs=epochs,  # Number of epochs\n",
    "    validation_data=val_dataset,  # Validation data\n",
    "    class_weight=class_weight_dict,  # Class weights\n",
    "    steps_per_epoch=len(train_df) // batch_size,  # Number of steps per epoch, optional if using tf.data.Dataset\n",
    "    validation_steps=len(val_df) // batch_size,  # Number of validation steps, optional if using tf.data.Dataset\n",
    "    verbose=1  # Show training log\n",
    "    # callbacks=[early_stopper, checkpoint]\n",
    ")\n",
    "\n",
    "# Save the training history for later analysis\n",
    "with open(f'logs/training_history_{timestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9d5c5aeb1cc415a3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation and Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2be1f2fa05673c8c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "test_generator.reset() # Ensuring the generator is reset to the beginning\n",
    "predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "predicted_classes = np.argmax(predictions, axis=1) # Convert predictions to class labels\n",
    "\n",
    "# Since the generator omits some samples due to rounding down in 'steps', we trim 'true_classes' to match 'predicted_classes' length\n",
    "true_classes = test_generator.classes\n",
    "true_classes = true_classes[:len(predicted_classes)]\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "\n",
    "# Additional weighted metric calculations\n",
    "weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "print(\"Weighted Precision:\", weighted_precision)\n",
    "print(\"Weighted Recall:\", weighted_recall)\n",
    "print(\"Weighted F1-Score:\", weighted_f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "db7fa3e6d1bb9f2c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a080149bf6c4f4b2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conducting error analysis\n",
    "This can be done by examining misclassified examples, which can provide insights into what types of errors the model is making"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebadbd1a2bde78ef"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Learning Curves\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb37bec40ecc9fb0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Precsion-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels for multi-class\n",
    "y_bin = label_binarize(true_classes, classes=np.arange(len(class_labels)))\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Compute precision-recall curve for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], predictions[:, i])\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='Class {}'.format(class_labels[i]))\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Precision vs. Recall curve\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d0bab63b4d1779c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ROC Curve and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Class {} (area = {:.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "219e556c37d15112"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
