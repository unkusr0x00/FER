{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from mtcnn import MTCNN\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from PIL import Image"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58fe4a12aecd81bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Date preperation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b58221bfc6a189aa"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define paths to your training and testing directories\n",
    "data_dir = 'Datasets/combined_dataset_processed_128_1'\n",
    "\n",
    "# Function to add images from a directory to a list\n",
    "def process_directory(directory, data_list):\n",
    "    for class_name in os.listdir(directory):\n",
    "        class_dir = os.path.join(directory, class_name)\n",
    "\n",
    "        # Check if it's a directory\n",
    "        if os.path.isdir(class_dir):\n",
    "            # Loop through each image in the folder\n",
    "            for image_name in os.listdir(class_dir):\n",
    "                image_path = os.path.join(class_dir, image_name)\n",
    "                # For test purposes use only processed images that DeepFace classifies correctly\n",
    "                # processed_image_path = image_path.replace('combined_dataset_deepface', 'combined_dataset_processed')\n",
    "                # Append to the data list\n",
    "                data_list.append({'filepath': image_path, 'label': class_name})\n",
    "\n",
    "# Initialize an empty list for storing data\n",
    "data_list = []\n",
    "# Add training images to the data list\n",
    "process_directory(data_dir, data_list)\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(data_list)\n",
    "# Shuffle the DataFrame\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "# Print the amount of images per category before balancing\n",
    "print(\"Images per category:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Split the data into training, validation, and test sets\n",
    "train_df, temp_test_val_df = train_test_split(df, train_size=0.7, random_state=42)\n",
    "test_df, val_df = train_test_split(temp_test_val_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Balance the test and validation sets\n",
    "# Determine the smallest class size within each of the test and validation sets\n",
    "min_test_class_size = test_df['label'].value_counts().min()\n",
    "min_val_class_size = val_df['label'].value_counts().min()\n",
    "\n",
    "# Determine the smallest size between the two for a uniform approach\n",
    "uniform_min_size = min(min_test_class_size, min_val_class_size)\n",
    "\n",
    "# Function to reduce class sizes\n",
    "def balance_classes(df, target_size):\n",
    "    balanced_df = pd.DataFrame()  # Initialize an empty DataFrame to hold the balanced data\n",
    "    for label in df['label'].unique():\n",
    "        subset = df[df['label'] == label].sample(n=target_size, random_state=42)\n",
    "        balanced_df = pd.concat([balanced_df, subset])\n",
    "    return balanced_df\n",
    "\n",
    "# Apply balancing\n",
    "test_df = balance_classes(test_df, uniform_min_size)\n",
    "val_df = balance_classes(val_df, uniform_min_size)\n",
    "\n",
    "# Calculate and print split ratios\n",
    "total_samples = len(df)\n",
    "train_ratio = len(train_df) / total_samples\n",
    "val_ratio = len(val_df) / total_samples\n",
    "test_ratio = len(test_df) / total_samples\n",
    "\n",
    "print(f\"\\nTotal samples: {total_samples}\")\n",
    "print(f\"Training set: {train_ratio:.2f} ({len(train_df)} samples)\")\n",
    "print(f\"Validation set: {val_ratio:.2f} ({len(val_df)} samples)\")\n",
    "print(f\"Test set: {test_ratio:.2f} ({len(test_df)} samples)\\n\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bfc7c488d9fce63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7ef247fbf08b2de2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Set the image size and batch size\n",
    "image_size = (128, 128)\n",
    "batch_size = 64\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation (optional)\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalize pixel values to [0, 1]\n",
    "    # rotation_range=15,  # rotation. Not needed since all images are getting aligned\n",
    "    width_shift_range=0.05, # horizontal shift (only 5% since faces are centered)\n",
    "    height_shift_range=0.05, # vertical shift (only 5% since faces are centered)\n",
    "    shear_range=0.1, \n",
    "    # zoom_range=0.1,   zoom (with current dataset not needed, since faces are centered)\n",
    "    horizontal_flip=True, # flip images horizontally\n",
    "    fill_mode='constant' # fill in missing pixels (nearest / constant)\n",
    "    # brightness_range=[0.8, 1.2] # darken and lighten images\n",
    ") \n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for validation data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)  # No augmentation for test data\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Compute class weights\n",
    "# Assuming 'labels' contains your class labels for the training data\n",
    "labels = train_df['label'].values\n",
    "unique_classes = np.unique(labels)\n",
    "# Compute class weights for balanced training\n",
    "class_weights = compute_class_weight('balanced', classes=unique_classes, y=labels)\n",
    "# Get class indices from the generator\n",
    "class_indices = train_generator.class_indices\n",
    "# Ensure the order of `unique_classes` matches the order in `class_indices`\n",
    "ordered_unique_classes = sorted(unique_classes, key=lambda x: class_indices[x])\n",
    "# Create a dictionary mapping class indices to their weights\n",
    "class_weights_dict = {class_indices[label]: weight for label, weight in zip(ordered_unique_classes, class_weights)}\n",
    "print(class_weights_dict)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b7d93af2fbe3e5c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Image before and after preprocessing comparison"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "694c0f982ff1c6a8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Create a non-preprocessing ImageDataGenerator\n",
    "no_preprocessing_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create a temporary generator to fetch a batch of original images\n",
    "temp_generator = no_preprocessing_datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    "    #shuffle=True  # Keep the same order as the original generator\n",
    ")\n",
    "\n",
    "# Function to plot images in a grid\n",
    "def plot_images_before(images_arr):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img.astype('uint8'))  # Cast to uint8 for correct image display\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Fetch a batch of original images\n",
    "original_batch = next(temp_generator)\n",
    "original_images = original_batch[0][:9]  # Select first 25 images\n",
    "\n",
    "# Function to plot images in a grid\n",
    "def plot_images_after(images_arr):\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img, cmap='gray')  # Set the colormap to 'gray'\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Get a batch of images\n",
    "example_batch = next(train_generator)\n",
    "example_images = example_batch[0][:9]  # Select first 25 images\n",
    "\n",
    "# Plot the images\n",
    "plot_images_before(original_images)\n",
    "plot_images_after(example_images)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd11bf6d52279ff5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Definition\n",
    "Previous model architecture neurons per layer: \n",
    "1. Start with images size (e.g. 224 for RAF-DB, 48 for FER2013) and divide by 2 for each convolutional layer\n",
    "2. Pyramidal model: double the number of filters for each convolutional layer, then halve the number of filters for each convolutional layer (e.g. 64, 128, 256, 128, 64)\n",
    "\n",
    "batch_size = 64, learning_rate = 0.0002, l2_reg = 0.002 and dropout = [0.1,0.3] give accuracy of about 50% 062527, 084021 \n",
    "batch_size = 64, learning_rate = 0.0002, l2_reg = 0.004 and dropout = [0.3,0.5] doesn't work, on about epoch 4-6 jumps in accuracy in loss and accuracy. Correction: better results are achieved. Overfitting was reduced. 090307, 101603\n",
    "batch_size = 256, learning_rate = 0.001, l2_reg = 0.004 and dropout = [0.3,0.5] very bad results. Probably learning rate\n",
    "\n",
    "model_checkpoint_20240224_170704.keras using new dataset\n",
    "model_checkpoint_20240225_085054.keras using DeepFace detected emotion images"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e710abf9909b4416"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 1)\n",
    "l2_reg = 0.001  # Regularization strength\n",
    "dropout = [0.15, 0,4]\n",
    "n_filter = [128, 64, 32, 128]\n",
    "\n",
    "model = Sequential([\n",
    "    # First Conv Block\n",
    "    Conv2D(n_filter[0], (3, 3), padding='same', activation='relu', input_shape=input_shape, kernel_regularizer=l2(l2_reg)), \n",
    "    BatchNormalization(), # Batch normalization normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation\n",
    "    MaxPooling2D(pool_size=(2, 2)), # Max pooling reduces computation by reducing the dimensionality of the feature maps\n",
    "    Dropout(dropout[0]), # Dropout to prevent overfitting\n",
    "    # Second Conv Block\n",
    "    Conv2D(n_filter[1], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(dropout[0]),\n",
    "    # Third Conv Block\n",
    "    Conv2D(n_filter[2], (3, 3), padding='same', activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Dropout(dropout[0]),\n",
    "    # Flatten and Dense Layers\n",
    "    Flatten(),\n",
    "    Dense(n_filter[3], activation='relu', kernel_regularizer=l2(l2_reg)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(dropout[1]),\n",
    "    Dense(7, activation='softmax', kernel_regularizer=l2(l2_reg))  # 7 emotions\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.0003), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e284df62c56685a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Callbacks"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a90a48042884bd52"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Early stopping to prevent overfitting. This stops training when the model's performance on the validation set starts to degrade.\n",
    "early_stopper = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to be monitored\n",
    "    patience=3,         # Number of epochs with no improvement after which training will be stopped\n",
    "    restore_best_weights=True  # Restores model weights from the epoch with the best value of the monitored metric\n",
    ")\n",
    "\n",
    "# ModelCheckpoint callback\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "checkpoint = ModelCheckpoint(\n",
    "    f'logs/model_checkpoint_{timestamp}.keras',  # Path where to save the model\n",
    "    monitor='val_loss',     # Metric to monitor\n",
    "    save_best_only=False,    # Save only the best model. Set False to save the model at the end of every epoch so restarting from specific epoch is possible\n",
    "    save_weights_only=False, # Save only the weights\n",
    "    mode='min',             # Minimize the monitored metric (val_loss) min before\n",
    "    verbose=1               # Verbose output\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=0.0001,\n",
    "    cooldown=3,\n",
    "    verbose=1\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3dd54d568955c19"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0386102718b852d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the last saved weights\n",
    "# model.load_weights('logs/model_checkpoint_20240225_085054.keras')\n",
    "\n",
    " # When resuming training, set epochs to the total number of epochs you want to train, not just the additional epochs. The model.fit() method continues training for the specified number of epochs, starting from the current epoch count.\n",
    "epochs = 50\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=val_generator.samples // val_generator.batch_size,\n",
    "    class_weight=class_weights_dict,\n",
    "    callbacks=[early_stopper, checkpoint, reduce_lr]\n",
    ")\n",
    "\n",
    "# Save the training history for later analysis\n",
    "with open(f'logs/training_history_{timestamp}.pkl', 'wb') as file:\n",
    "    pickle.dump(history.history, file)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18f2de33592e5862"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation and Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae496200b99ecef6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "test_generator.reset() # Ensuring the generator is reset to the beginning\n",
    "predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "predicted_classes = np.argmax(predictions, axis=1) # Convert predictions to class labels\n",
    "\n",
    "# Since the generator omits some samples due to rounding down in 'steps', trim 'true_classes' to match 'predicted_classes' length\n",
    "true_classes = test_generator.classes\n",
    "true_classes = true_classes[:len(predicted_classes)]\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "\n",
    "# Additional weighted metric calculations\n",
    "weighted_precision = precision_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_recall = recall_score(true_classes, predicted_classes, average='weighted')\n",
    "weighted_f1 = f1_score(true_classes, predicted_classes, average='weighted')\n",
    "\n",
    "print(\"Weighted Precision:\", weighted_precision)\n",
    "print(\"Weighted Recall:\", weighted_recall)\n",
    "print(\"Weighted F1-Score:\", weighted_f1)\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fc382fa13b41325"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4401eeb53e94c63d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conducting error analysis\n",
    "This can be done by examining misclassified examples, which can provide insights into what types of errors the model is making"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c425d5531b694d5"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Learning Curves\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5018019f898ec75"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Precsion-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Binarize the labels for multi-class\n",
    "y_bin = label_binarize(true_classes, classes=np.arange(len(class_labels)))\n",
    "n_classes = y_bin.shape[1]\n",
    "\n",
    "# Compute precision-recall curve for each class\n",
    "precision = dict()\n",
    "recall = dict()\n",
    "for i in range(n_classes):\n",
    "    precision[i], recall[i], _ = precision_recall_curve(y_bin[:, i], predictions[:, i])\n",
    "\n",
    "# Plot the precision-recall curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(recall[i], precision[i], lw=2, label='Class {}'.format(class_labels[i]))\n",
    "\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.title(\"Precision vs. Recall curve\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ffef5ae7733c8b07"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ROC Curve and AUC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_bin[:, i], predictions[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve\n",
    "for i in range(n_classes):\n",
    "    plt.plot(fpr[i], tpr[i], label='Class {} (area = {:.2f})'.format(class_labels[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c1d6f488966f46d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
