{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-12T10:26:52.888097Z",
     "start_time": "2024-02-12T10:26:35.787892Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-12 11:26:42.650540: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12271 images belonging to 7 classes.\n",
      "Found 3068 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths to your training and testing directories\n",
    "train_dir = 'Datasets/RAF-DB/DATASET/train'\n",
    "test_dir = 'Datasets/RAF-DB/DATASET/test'\n",
    "\n",
    "# Set the image size for ResNet50V2\n",
    "image_size = (224, 224)  # ResNet50V2 expects 224x224 input\n",
    "batch_size = 64\n",
    "\n",
    "# Data augmentation for the training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,  # Use ResNet specific preprocessing\n",
    "    rotation_range=15,   # reduced from 30\n",
    "    width_shift_range=0.1,   # reduced from 0.2\n",
    "    height_shift_range=0.1,  # reduced from 0.2\n",
    "    shear_range=0.1,    # reduced from 0.2\n",
    "    zoom_range=0.1, # reduced from 0.2\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='constant'    # instead of 'nearest' because of blur\n",
    ")\n",
    "\n",
    "# Data generator for the test set (no augmentation, just rescaling)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Load images from directories and resize them\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T13:25:17.962286Z",
     "start_time": "2024-01-22T13:25:17.304366Z"
    }
   },
   "id": "518379f540b487a5",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "train_generator and test_generator are now ready to be used in model training and evaluation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c665c1e09bba0381"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)   (None, 230, 230, 3)          0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)         (None, 112, 112, 64)         9472      ['conv1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)   (None, 114, 114, 64)         0         ['conv1_conv[0][0]']          \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)   (None, 56, 56, 64)           0         ['pool1_pad[0][0]']           \n",
      "                                                                                                  \n",
      " conv2_block1_preact_bn (Ba  (None, 56, 56, 64)           256       ['pool1_pool[0][0]']          \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block1_preact_relu (  (None, 56, 56, 64)           0         ['conv2_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2  (None, 56, 56, 64)           4096      ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_0_conv[0][0]', \n",
      "                                                                     'conv2_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block2_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block2_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2  (None, 56, 56, 64)           36864     ['conv2_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2  (None, 56, 56, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_out (Add)      (None, 56, 56, 256)          0         ['conv2_block1_out[0][0]',    \n",
      "                                                                     'conv2_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv2_block3_preact_bn (Ba  (None, 56, 56, 256)          1024      ['conv2_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2_block3_preact_relu (  (None, 56, 56, 256)          0         ['conv2_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2  (None, 56, 56, 64)           16384     ['conv2_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNo  (None, 56, 56, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activ  (None, 56, 56, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv2_block3_2_pad (ZeroPa  (None, 58, 58, 64)           0         ['conv2_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2  (None, 28, 28, 64)           36864     ['conv2_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNo  (None, 28, 28, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activ  (None, 28, 28, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 28, 28, 256)          0         ['conv2_block2_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2  (None, 28, 28, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_out (Add)      (None, 28, 28, 256)          0         ['max_pooling2d_3[0][0]',     \n",
      "                                                                     'conv2_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block1_preact_bn (Ba  (None, 28, 28, 256)          1024      ['conv2_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block1_preact_relu (  (None, 28, 28, 256)          0         ['conv3_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2  (None, 28, 28, 128)          32768     ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2  (None, 28, 28, 512)          131584    ['conv3_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_0_conv[0][0]', \n",
      "                                                                     'conv3_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block2_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block2_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_out (Add)      (None, 28, 28, 512)          0         ['conv3_block1_out[0][0]',    \n",
      "                                                                     'conv3_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block3_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block3_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2  (None, 28, 28, 128)          147456    ['conv3_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2  (None, 28, 28, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_out (Add)      (None, 28, 28, 512)          0         ['conv3_block2_out[0][0]',    \n",
      "                                                                     'conv3_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv3_block4_preact_bn (Ba  (None, 28, 28, 512)          2048      ['conv3_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv3_block4_preact_relu (  (None, 28, 28, 512)          0         ['conv3_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2  (None, 28, 28, 128)          65536     ['conv3_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNo  (None, 28, 28, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activ  (None, 28, 28, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv3_block4_2_pad (ZeroPa  (None, 30, 30, 128)          0         ['conv3_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2  (None, 14, 14, 128)          147456    ['conv3_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNo  (None, 14, 14, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activ  (None, 14, 14, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 14, 14, 512)          0         ['conv3_block3_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2  (None, 14, 14, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_out (Add)      (None, 14, 14, 512)          0         ['max_pooling2d_4[0][0]',     \n",
      "                                                                     'conv3_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block1_preact_bn (Ba  (None, 14, 14, 512)          2048      ['conv3_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block1_preact_relu (  (None, 14, 14, 512)          0         ['conv4_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2  (None, 14, 14, 256)          131072    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2  (None, 14, 14, 1024)         525312    ['conv4_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_0_conv[0][0]', \n",
      "                                                                     'conv4_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block2_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block2_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block1_out[0][0]',    \n",
      "                                                                     'conv4_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block3_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block3_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block2_out[0][0]',    \n",
      "                                                                     'conv4_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block4_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block3_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block4_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block4_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block4_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block4_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block4_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block4_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block4_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block4_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block3_out[0][0]',    \n",
      "                                                                     'conv4_block4_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block5_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block4_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block5_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block5_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block5_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block5_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2  (None, 14, 14, 256)          589824    ['conv4_block5_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block5_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block5_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2  (None, 14, 14, 1024)         263168    ['conv4_block5_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_out (Add)      (None, 14, 14, 1024)         0         ['conv4_block4_out[0][0]',    \n",
      "                                                                     'conv4_block5_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv4_block6_preact_bn (Ba  (None, 14, 14, 1024)         4096      ['conv4_block5_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv4_block6_preact_relu (  (None, 14, 14, 1024)         0         ['conv4_block6_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2  (None, 14, 14, 256)          262144    ['conv4_block6_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNo  (None, 14, 14, 256)          1024      ['conv4_block6_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activ  (None, 14, 14, 256)          0         ['conv4_block6_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv4_block6_2_pad (ZeroPa  (None, 16, 16, 256)          0         ['conv4_block6_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2  (None, 7, 7, 256)            589824    ['conv4_block6_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNo  (None, 7, 7, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activ  (None, 7, 7, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 7, 7, 1024)           0         ['conv4_block5_out[0][0]']    \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2  (None, 7, 7, 1024)           263168    ['conv4_block6_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_out (Add)      (None, 7, 7, 1024)           0         ['max_pooling2d_5[0][0]',     \n",
      "                                                                     'conv4_block6_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block1_preact_bn (Ba  (None, 7, 7, 1024)           4096      ['conv4_block6_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block1_preact_relu (  (None, 7, 7, 1024)           0         ['conv5_block1_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2  (None, 7, 7, 512)            524288    ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block1_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block1_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block1_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block1_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block1_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block1_0_conv (Conv2  (None, 7, 7, 2048)           2099200   ['conv5_block1_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block1_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block1_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_0_conv[0][0]', \n",
      "                                                                     'conv5_block1_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block2_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block1_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block2_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block2_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block2_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block2_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block2_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block2_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block2_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block2_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block2_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block2_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block1_out[0][0]',    \n",
      "                                                                     'conv5_block2_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " conv5_block3_preact_bn (Ba  (None, 7, 7, 2048)           8192      ['conv5_block2_out[0][0]']    \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv5_block3_preact_relu (  (None, 7, 7, 2048)           0         ['conv5_block3_preact_bn[0][0]\n",
      " Activation)                                                        ']                            \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2  (None, 7, 7, 512)            1048576   ['conv5_block3_preact_relu[0][\n",
      " D)                                                                 0]']                          \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_1_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_1_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_2_pad (ZeroPa  (None, 9, 9, 512)            0         ['conv5_block3_1_relu[0][0]'] \n",
      " dding2D)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2  (None, 7, 7, 512)            2359296   ['conv5_block3_2_pad[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_bn (BatchNo  (None, 7, 7, 512)            2048      ['conv5_block3_2_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv5_block3_2_relu (Activ  (None, 7, 7, 512)            0         ['conv5_block3_2_bn[0][0]']   \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " conv5_block3_3_conv (Conv2  (None, 7, 7, 2048)           1050624   ['conv5_block3_2_relu[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_out (Add)      (None, 7, 7, 2048)           0         ['conv5_block2_out[0][0]',    \n",
      "                                                                     'conv5_block3_3_conv[0][0]'] \n",
      "                                                                                                  \n",
      " post_bn (BatchNormalizatio  (None, 7, 7, 2048)           8192      ['conv5_block3_out[0][0]']    \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " post_relu (Activation)      (None, 7, 7, 2048)           0         ['post_bn[0][0]']             \n",
      "                                                                                                  \n",
      " global_average_pooling2d (  (None, 2048)                 0         ['post_relu[0][0]']           \n",
      " GlobalAveragePooling2D)                                                                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 1024)                 2098176   ['global_average_pooling2d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1024)                 4096      ['dense[0][0]']               \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 1024)                 0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 7)                    7175      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 25674247 (97.94 MB)\n",
      "Trainable params: 2107399 (8.04 MB)\n",
      "Non-trainable params: 23566848 (89.90 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Load the ResNet50V2 model without the top layer\n",
    "base_model = ResNet50V2(weights=None, include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.load_weights('PretrainedModels/ResNet50V2/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Add custom top layers\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(7, activation='softmax')(x)  # Assuming 7 emotions\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Add your existing code for predictions, classification report, and confusion matrix here"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T12:34:57.967307Z",
     "start_time": "2024-01-20T12:34:54.989806Z"
    }
   },
   "id": "d542622cdcf7878",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "191/191 [==============================] - 666s 3s/step - loss: 2.2427 - accuracy: 0.3421 - val_loss: 1.4452 - val_accuracy: 0.5100\n",
      "Epoch 2/15\n",
      "191/191 [==============================] - 698s 4s/step - loss: 1.8388 - accuracy: 0.4429 - val_loss: 1.2097 - val_accuracy: 0.5851\n",
      "Epoch 3/15\n",
      "191/191 [==============================] - 696s 4s/step - loss: 1.6972 - accuracy: 0.4706 - val_loss: 1.1817 - val_accuracy: 0.5991\n",
      "Epoch 4/15\n",
      "191/191 [==============================] - 691s 4s/step - loss: 1.5948 - accuracy: 0.4991 - val_loss: 1.1539 - val_accuracy: 0.6064\n",
      "Epoch 5/15\n",
      "191/191 [==============================] - 691s 4s/step - loss: 1.5230 - accuracy: 0.5071 - val_loss: 1.1108 - val_accuracy: 0.6150\n",
      "Epoch 6/15\n",
      "191/191 [==============================] - 679s 4s/step - loss: 1.4416 - accuracy: 0.5249 - val_loss: 1.1085 - val_accuracy: 0.6210\n",
      "Epoch 7/15\n",
      "191/191 [==============================] - 694s 4s/step - loss: 1.4187 - accuracy: 0.5324 - val_loss: 1.0643 - val_accuracy: 0.6290\n",
      "Epoch 8/15\n",
      "191/191 [==============================] - 700s 4s/step - loss: 1.3620 - accuracy: 0.5472 - val_loss: 1.0592 - val_accuracy: 0.6316\n",
      "Epoch 9/15\n",
      "191/191 [==============================] - 696s 4s/step - loss: 1.3474 - accuracy: 0.5444 - val_loss: 1.0571 - val_accuracy: 0.6323\n",
      "Epoch 10/15\n",
      "191/191 [==============================] - 695s 4s/step - loss: 1.3215 - accuracy: 0.5485 - val_loss: 1.0163 - val_accuracy: 0.6423\n",
      "Epoch 11/15\n",
      "191/191 [==============================] - 693s 4s/step - loss: 1.2928 - accuracy: 0.5598 - val_loss: 1.0130 - val_accuracy: 0.6373\n",
      "Epoch 12/15\n",
      "191/191 [==============================] - 695s 4s/step - loss: 1.2730 - accuracy: 0.5602 - val_loss: 1.0138 - val_accuracy: 0.6433\n",
      "Epoch 13/15\n",
      "191/191 [==============================] - 693s 4s/step - loss: 1.2602 - accuracy: 0.5639 - val_loss: 1.0180 - val_accuracy: 0.6443\n",
      "Epoch 14/15\n",
      "191/191 [==============================] - 689s 4s/step - loss: 1.2212 - accuracy: 0.5721 - val_loss: 0.9896 - val_accuracy: 0.6496\n",
      "Epoch 15/15\n",
      "191/191 [==============================] - 690s 4s/step - loss: 1.2066 - accuracy: 0.5744 - val_loss: 0.9892 - val_accuracy: 0.6459\n"
     ]
    }
   ],
   "source": [
    "epochs = 15  # Increased number of epochs\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-20T15:27:48.660338Z",
     "start_time": "2024-01-20T12:35:02.020936Z"
    }
   },
   "id": "d8e18494f5b0d9f6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 139s 3s/step - loss: 0.9846 - accuracy: 0.6490\n",
      "Test accuracy:  0.6489569544792175\n",
      "48/48 [==============================] - 138s 3s/step\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.09      0.09      0.09       329\n",
      "           2       0.00      0.00      0.00        74\n",
      "           3       0.04      0.01      0.02       160\n",
      "           4       0.38      0.44      0.41      1185\n",
      "           5       0.16      0.15      0.16       478\n",
      "           6       0.08      0.06      0.07       162\n",
      "           7       0.24      0.25      0.25       680\n",
      "\n",
      "    accuracy                           0.26      3068\n",
      "   macro avg       0.14      0.14      0.14      3068\n",
      "weighted avg       0.24      0.26      0.25      3068\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x1000 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "print(\"Test accuracy: \", test_accuracy)\n",
    "\n",
    "# Predictions on the test set\n",
    "test_generator.reset()\n",
    "predictions = model.predict(test_generator, steps=np.ceil(test_generator.samples / test_generator.batch_size))\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Since the generator omits some samples due to rounding down in 'steps', we trim 'true_classes' to match 'predicted_classes' length\n",
    "true_classes = test_generator.classes\n",
    "true_classes = true_classes[:len(predicted_classes)]\n",
    "\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(true_classes, predicted_classes, target_names=class_labels, zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_classes, predicted_classes)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-22T07:30:11.464136Z",
     "start_time": "2024-01-22T07:25:30.550082Z"
    }
   },
   "id": "46691c52a9691d78",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Conducting error analysis\n",
    "This can be done by examining misclassified examples, which can provide insights into what types of errors the model is making"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608e3da9e8b70395"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
